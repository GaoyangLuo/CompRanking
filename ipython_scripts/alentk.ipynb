{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract informations from seqs in fasta files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire seq length\n",
    "### How to use:\n",
    "First we need an `input directory`, containing fasta files and corressponding blast output, which are using suffix as 'basename'.fa and 'basename'.blast.out respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fa=\"/lomi_home/gaoyang/software/CompRanking/benchmarking/MGE_benchmarking/plasclass/fq/2_assembly/DRR016448.contigs.fa\"\n",
    "# input_blastout=\"/lomi_home/gaoyang/software/CompRanking/benchmarking/MGE_benchmarking/plasclass/fq/2_assembly/DRR016448.contigs.fa.blast.out\"\n",
    "input_dir=\"/lomi_home/gaoyang/software/CompRanking/benchmarking/MGE_benchmarking/plasclass/fq/2_assembly/blastout_plasmid\"\n",
    "# b=filename=os.path.splitext(os.path.basename(input_fa))[0]\n",
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contigLen(input_fa):\n",
    "    \"\"\"\n",
    "    input -> fasta file\n",
    "    return -> {ID:length}\n",
    "    \"\"\"\n",
    "    contigLen_dic={}\n",
    "    #load fasta\n",
    "    INPUT_FASTA=open(input_fa, \"r\")\n",
    "    for record in SeqIO.parse(INPUT_FASTA, 'fasta'):\n",
    "        contigLen_dic.setdefault(str(record.id), len(str(record.seq)))\n",
    "    return contigLen_dic\n",
    "# .split(\" \")[0].strip(\">\")\n",
    "def get_alignLen(input_blastout):\n",
    "    \"\"\"\n",
    "    input -> blast .out file\n",
    "    return -> {ID:alignment length}\n",
    "    \"\"\"\n",
    "    aligenLen_dic={}\n",
    "    INPUT_BLASTOUT=pd.read_csv(input_blastout, sep='\\t', header=None)\n",
    "    INPUT_BLASTOUT.columns = ['id', 'sub_id', 'identity', 'alignLen', 'mismat', 'gapOpens', 'qStart', 'qEnd', 'sStart', 'sEnd', 'eval', 'bit']\n",
    "    for i, record in INPUT_BLASTOUT.iterrows():\n",
    "        aligenLen_dic.setdefault(str(record['id']), [int(record['identity']), int(record['alignLen'])])\n",
    "    return aligenLen_dic\n",
    "\n",
    "def extract_subseq(seqName_list,input_fa):\n",
    "    \"\"\"\n",
    "    input: seqID -> list; fasta file\n",
    "    return: .length file and dic{>seqID \\n \"ATCG...\"}\n",
    "    \"\"\"\n",
    "    subseq_dic={}\n",
    "    seqNameList=seqName_list\n",
    "    INPUT_FASTA = open(input_fa, 'r')\n",
    "    filename=os.path.splitext(os.path.basename(input_fa))[0]\n",
    "    filename_path=os.path.splitext(input_fa)[0]\n",
    "    with open(filename_path+\".length\", 'w') as f:\n",
    "        for record in SeqIO.parse(INPUT_FASTA, 'fasta'):\n",
    "            if str(record.id) in seqNameList:\n",
    "                subseq_dic.setdefault(str(record.id),\n",
    "                    str(record.seq))\n",
    "                f.write(\">\"+str(record.id)+\"_\"+filename.spilt(\".\")[0]+\" \"+str(len(record.seq)) + '\\n' + str(record.seq) + '\\n')\n",
    "            else:\n",
    "                continue\n",
    "        f.close()\n",
    "    return subseq_dic\n",
    "\n",
    "def extract_subseq_dic(seqName_list,input_fa):\n",
    "    \"\"\"\n",
    "    input: seqID -> list; fasta file\n",
    "    return: .length file and dic{>seqID \\n \"ATCG...\"}\n",
    "    \"\"\"\n",
    "    subseq_dic={}\n",
    "    seqNameList=seqName_list\n",
    "    INPUT_FASTA = open(input_fa, 'r')\n",
    "    filename=os.path.splitext(os.path.basename(input_fa))[0]\n",
    "    filename_path=os.path.splitext(input_fa)[0]\n",
    "    # with open(filename_path+\".length\", 'w') as f:\n",
    "    for record in SeqIO.parse(INPUT_FASTA, 'fasta'):\n",
    "        if str(record.id) in seqNameList:\n",
    "            subseq_dic.setdefault(str(record.id),\n",
    "                len(str(record.seq)))\n",
    "        else:\n",
    "            continue\n",
    "        # f.close()\n",
    "    return subseq_dic\n",
    "\n",
    "def extract_subseq_lengthFilter(seqName_list,input_fa,k):\n",
    "    \"\"\"\n",
    "    input: fasta file, set k and list storing seqID\n",
    "    extract exact seqs of length of interest from target file\n",
    "    \"\"\"\n",
    "    subseq_dic={}\n",
    "    seqNameList=seqName_list\n",
    "    INPUT_FASTA = open(input_fa, 'r')\n",
    "    filename=os.path.splitext(os.path.basename(input_fa))[0]\n",
    "    filename_path=os.path.splitext(input_fa)[0]\n",
    "    with open(filename_path+\"_\"+k+\"k\"+\".fasta\", 'w') as f:\n",
    "        for record in SeqIO.parse(INPUT_FASTA, 'fasta'):\n",
    "            if str(record.id) in seqNameList:\n",
    "                f.write(\">\"+str(record.id)+\"_\"+filename.split(\".\")[0]+\" \"+ \"len=\"+str(\n",
    "                    len(record.seq)) + '\\n' + str(record.seq) + '\\n')\n",
    "            else:\n",
    "                continue\n",
    "        f.close()\n",
    "    return subseq_dic\n",
    "\n",
    "def extract_subseq_nseq(number_of_seqs, input_fa):\n",
    "    \"\"\"\n",
    "    input: fasta file\n",
    "    extract exact number of seqs from target file\n",
    "    \"\"\"\n",
    "    count=0\n",
    "    ult=int(number_of_seqs)\n",
    "    INPUT_FASTA = open(input_fa, 'r')\n",
    "    filename_path=os.path.splitext(input_fa)[0]\n",
    "    with open(filename_path+\"_\"+str(number_of_seqs)+\"seqs.fasta\", 'w') as f:\n",
    "        for record in SeqIO.parse(INPUT_FASTA, 'fasta'):\n",
    "            if count <= ult:\n",
    "                f.write(\">\"+str(record.id) + '\\n'  + str(\n",
    "                    record.seq) + '\\n')\n",
    "                count += 1\n",
    "            else:\n",
    "                break\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k141_10': 'CTATCTCCACCTCAATAAAATACTCGTTACTAAAGGGGCCAGGGTTACCCGGGGAGGCGCTATTGCGTTATCCGGTAACAGCGGACGTTCATCCGGTCCTCATCTGCATTACGAGCTGGTCATCAATAACAATCCTGTTAACTCACTGGCGTTCCGGGCAGCGGCACCCGCTGATAACAAACTTGAACAGCATGCCTTTGCGCATGCCAGAGACTACGAACGATACCTGGACTGATAACGGGGCCGCGACGCGGCCCCGTCTGCCGGATTAATTTTTTTTATCGTTTTCACTTCCTTGATGTTGATGATCTCCATGCCCTCCGTGGCCGTGGAAAAGATGCATTAGC',\n",
       " 'k141_60': 'AATATGGGGCTCATGTCCTGCTACGTAACCCGTCAGTAAAGCCCTGCTGCGCACCTGACGCTAAGCACTAACCCGCCTGCAGTTACCTGGTCGAATACAGCCCGCGAAGCTTTCTTGCCTGCGTCTGATGTGCTTCCGCACCGGCATTATTGACCTGCTCATGCACGAGAGCGGCTTTTTCTCCGGCATTCAGTTCGTTAAAAGAAGAAGACGAGGTCTTTGAATTTGCATCACTGCCGGACAGCATTTTTTTATGTTCCTCAATCATTTTCTGATGCGCATAGGACGCGCTGTTGTTCATAAATGAATGAGCAACAATGGCCCTTTCATGTTCATTCATTTCAGAGAATGAGGGCGTGT',\n",
       " 'k141_66': 'ACCGTCCTGAAAAGCCAGACGGCAGACGGGCTGTATTACGCAGCCAGGTACTTGAACTGCATGGCATCAGCCACGGCTCTGCCGGAGCAAGAAGCATCGCCACAATGGCAACCCAGAGAGGCTACCAGATGGGGCGCTGGCTTGCTGGCAGACTCATGAAAGAGCTGGGGCTGGTCAGTTGCCAGCAGCCGACTCACCGGTATAAGCGTGGCGGTCATGAGCACGTTGCTATCCCGAATCATCTTGAGCGACAGTTCGCCGTAACGGAACCAAATCAGGTGTGGTGCGGTGATGTGACCTATAGTGTGCCCGGAGTTCAGGGCGGGCATGGATGCTTAAATGAACCGCGAGTCTGTCTGGAATATTGAACCGGTAACTCACGATGAGAAACCCAACAATCCCACCGGGTGTGACGGTGGAGAACCTGAGCGGCAGTGACCTGCGGCATGCCCGCAGGGTGATGTAACCCGCTGACAACGGGGATTGAGGCGAGATCACTAAGCCGAGATGATCCTCAAGGTTAAGTACTGAAAGGCTGAAGAACATGAACCCGTTAATCCGCCTCTGTGGGTTGAAAACGTCACCACGGCCTACGTGATCTGACAGGCCGTGCAGGAGGAACTGGCAGTGATACGTAAGCACTGCCGGTCGAAGGT',\n",
       " 'k141_360': 'GCCGCCGGCATAAGAGTGCCTGCTGCCGGCGTCCCGTTATCAGCCGTTCCGCTGACTATTCGATTCGCTGGAAGACTTTTTTACTGCCCTCCGGTGAGAATGCGATAACATCGTAAGCCTCTTTTCGGGCCCCCATCTCCATTCCCGGACTTCCTGCTGGCATACCGGGGGTGGCGAGACCGTATATACCCGAACCAGACTGCATGGCCTTATGTATCGTTGCCGCAGGCACATGGCCTTCAATGATCAAATTACCTACAACCGCGGTATGACAACTTCGTAGTCCAGCAGGAACAGCATGCTTTTCTTTCAGGGCTGACAGCGCCTGATCATTCATGACGTGAGTTCGCACTTCGAA',\n",
       " 'k141_709': 'AATTCCCGTCGTGTAGATAACTACGATACGGGAGGGCTTACCATCTGGCCCCAGTGCTGCAATGATACCGCGAGACCCACGCTCACCGGCTCCAGATTTATCAGCAATAAACCAGCCAGCCGGAAGGGCCGAGCGCAGAAGTGGTCCTGCAACTTTATCCGCCTCCATCCAGTCTATTAATTGTTGCCGGGAAGCTAGAGTAAGTAGTTCGCCAGTTAATAGTTTGCGCAACGTTGTTGCCATTGCTACAGGCATCGTGGTGTCACGCTCGTCGTTTGGTATGGCTTCATTCAGCTCCGGTTCCCAACGATCAAGGCGAGTTACATGATCCCCCATGTTGTGCAAAAAAGCGGTTA',\n",
       " 'k141_923': 'CGCCAGTGAACCCGGACGATATAATCAGCTTCTCCAAAAGCAAGTGAGCGGATACATTCGGGACGCGAACCGAATCCCCGGTCAGCAATGCGTATCTCGTCTGCCGTTTGCGCAAATCGGTCCAGCCGTTCAGCGTCTCTGCTGTCGGTTAGCTCAAAATCAGTGAACTGACAGGTATGAGGATCATATCCCATATGTAGTCGCCATTCAGCGCTGCCGCCCCCGGGCGCACTGATTGCTGTTCCATCGACAAGACGCAATCTCTTTCCGCTTGTACAACCCGTAACTGCGGCGCGTACAGCAAGTGTTTGTGCGGCAAGTATGCCAAACCAGTCGGCGGCATTCCGCA',\n",
       " 'k141_952': 'CCGCGATGGCAAAAGCTGAAAAGCTGGCCGAGACCGACAGGCGCGATGCCAAGCAGAACGAGGAGCTCAGCACCTTGCTGTCGTCCGTGCGCACGGAGATCGAGATGGCGCAGATCCTGGGTTATGGCAAGAAGGCGGACTTCAAACCCATTTTCGATCAGGTGAAGTCCATTGAGCAAAAGTCGGCTGGTGGCAAAAGCGGCAAGGGATGGTTCGACGAGTTGAAGACGCGCATCCAAAAGCTGTTTTGAGGTGATGAAGGGGCTGACTGCTCTGTCGGTCAGTCTCGCGATGTTCGCATTCAGCCCCAAC',\n",
       " 'k141_982': 'ACTCTCTTTACCAATTCTGCCCCGAATTACACTTAAAACGACTCAACAGCTTAACGTTGGCTTGCCACGCATTACTTGACTGTAAAACTCTCACTCTTACCGAACTTGGCCGTAACCTGCCAACCAAAGCGAGAACAAAACATAACATCAAACGAATCGACCGATTGTTAGGTAATCGTCACCTCCACAAAGAGCGACTCGCTGTATACCGTTGGCATGCTAGCTTTATCTGTTCGGGCAATACGATGCCCATTGTACTTGTTGACTGGTCTGATATTCGTGAGCAAAAACGACTTATGGTATTGCGAGCTTCAGTCGCACTACACGGTCGTTCTGTTACTCTTTATGAGAAAGCGTTCCC'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contigLen_1=get_contigLen(input_fa)\n",
    "# alignLen_1=get_alignLen(input_blastout)\n",
    "\n",
    "# # print(get_contigLen(input_fa))\n",
    "# # print(get_alignLen(input_blastout))\n",
    "# tmp_list=[]\n",
    "# for i in alignLen_1:\n",
    "#     if alignLen_1[i][0] >= 95 and (alignLen_1[i][1] / contigLen_1[i]) >= 0.95:\n",
    "#         tmp_list.append(str(i))\n",
    "\n",
    "# a=tmp_list\n",
    "# extract_subseq(a,input_fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/lomi_home/gaoyang/software/CompRanking/benchmarking/MGE_benchmarking/plasclass/fq/2_assembly/DRR016448.contigs.fa.blast.out'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [85], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m input_fa\u001b[39m=\u001b[39mi\n\u001b[1;32m      7\u001b[0m contigLen_1\u001b[39m=\u001b[39mget_contigLen(input_fa)\n\u001b[0;32m----> 8\u001b[0m alignLen_1\u001b[39m=\u001b[39mget_alignLen(input_blastout)\n\u001b[1;32m     10\u001b[0m \u001b[39m# print(get_contigLen(input_fa))\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# print(get_alignLen(input_blastout))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m tmp_list\u001b[39m=\u001b[39m[]\n",
      "Cell \u001b[0;32mIn [84], line 19\u001b[0m, in \u001b[0;36mget_alignLen\u001b[0;34m(input_blastout)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39minput -> blast .out file\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mreturn -> {ID:alignment length}\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m aligenLen_dic\u001b[39m=\u001b[39m{}\n\u001b[0;32m---> 19\u001b[0m INPUT_BLASTOUT\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(input_blastout, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     20\u001b[0m INPUT_BLASTOUT\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msub_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39midentity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39malignLen\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmismat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgapOpens\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mqStart\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mqEnd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msStart\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msEnd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbit\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m i, record \u001b[39min\u001b[39;00m INPUT_BLASTOUT\u001b[39m.\u001b[39miterrows():\n",
      "File \u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m     f,\n\u001b[1;32m   1219\u001b[0m     mode,\n\u001b[1;32m   1220\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1223\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1224\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1225\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1226\u001b[0m )\n\u001b[1;32m   1227\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/lomi_home/gaoyang/software/CompRanking/benchmarking/MGE_benchmarking/plasclass/fq/2_assembly/DRR016448.contigs.fa.blast.out'"
     ]
    }
   ],
   "source": [
    "#generate fitered sequence \n",
    "for i in glob.glob(input_dir+\"/*fa\"):\n",
    "    file_basename=os.path.splitext(os.path.basename(i))[0]\n",
    "    input_blastout=input_dir + \"/\" + file_basename + \".fa.blast.out\"\n",
    "    input_fa=i\n",
    "    \n",
    "    contigLen_1=get_contigLen(input_fa)\n",
    "    alignLen_1=get_alignLen(input_blastout)\n",
    "\n",
    "    # print(get_contigLen(input_fa))\n",
    "    # print(get_alignLen(input_blastout))\n",
    "    tmp_list=[]\n",
    "    for i in alignLen_1:\n",
    "        if alignLen_1[i][0] >= 95 and (alignLen_1[i][1] / contigLen_1[i]) >= 0.95:\n",
    "            tmp_list.append(str(i))\n",
    "\n",
    "    a=tmp_list\n",
    "    extract_subseq(a,input_fa)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # print(blast_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575 637 470 944 522\n"
     ]
    }
   ],
   "source": [
    "#length statistic for plasmid\n",
    "input_dir=\"/lomi_home/gaoyang/software/CompRanking/benchmarking/MGE_benchmarking/plasclass/fq/2_assembly/blastout_plasmid\"\n",
    "length0_300=0\n",
    "length300_500=0\n",
    "length500_1000=0\n",
    "length1000_5000=0\n",
    "length5000_=0\n",
    "\n",
    "for i in glob.glob(input_dir+\"/*fa\"):\n",
    "    ls0_300=[]\n",
    "    ls300_500=[]\n",
    "    ls500_1000=[]\n",
    "    ls1000_5000=[]\n",
    "    ls5000_=[]\n",
    "    file_basename=os.path.splitext(os.path.basename(i))[0]\n",
    "    input_blastout=input_dir + \"/\" + file_basename + \".fa.blast.out\"\n",
    "    input_fa=i\n",
    "    \n",
    "    contigLen_1=get_contigLen(input_fa)\n",
    "    alignLen_1=get_alignLen(input_blastout)\n",
    "    tmp_list=[]\n",
    "    for i in alignLen_1:\n",
    "        if alignLen_1[i][0] >= 95 and (alignLen_1[i][1] / contigLen_1[i]) >= 0.95:\n",
    "            tmp_list.append(str(i))\n",
    "\n",
    "    a=tmp_list\n",
    "    subseq_dic=extract_subseq_dic(a,input_fa)\n",
    "    \n",
    "    for j in subseq_dic:\n",
    "        if subseq_dic[j] <=300:\n",
    "            length0_300 += 1\n",
    "            ls0_300.append(j)\n",
    "        elif 300<=subseq_dic[j] < 500:\n",
    "            length300_500 += 1\n",
    "            ls300_500.append(j)\n",
    "        elif 500 <= subseq_dic[j] < 1000:\n",
    "            length500_1000 += 1\n",
    "            ls500_1000.append(j)\n",
    "        elif 1000 <= subseq_dic[j] < 5000:\n",
    "            length1000_5000 += 1\n",
    "            ls1000_5000.append(j)\n",
    "        elif 5000 <= subseq_dic[j]:\n",
    "            length5000_ += 1    \n",
    "            ls5000_.append(j)\n",
    "        \n",
    "    # extract_subseq_lengthFilter(ls0_300,input_fa,\"0.3\")\n",
    "    extract_subseq_lengthFilter(ls300_500,input_fa,\"0.5\")\n",
    "    extract_subseq_lengthFilter(ls500_1000,input_fa,\"1\")\n",
    "    extract_subseq_lengthFilter(ls1000_5000,input_fa,\"5\")\n",
    "    extract_subseq_lengthFilter(ls5000_,input_fa,\"lt5\")\n",
    "\n",
    "print(length0_300,\n",
    "length300_500,\n",
    "length500_1000,\n",
    "length1000_5000,\n",
    "length5000_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1404 3263 3181 7575 6531\n"
     ]
    }
   ],
   "source": [
    "#length statistic for chormosome\n",
    "input_dir=\"/lomi_home/gaoyang/software/CompRanking/benchmarking/MGE_benchmarking/plasclass/fq/2_assembly/blastout_chromosome\"\n",
    "\n",
    "length0_300=0\n",
    "length300_500=0\n",
    "length500_1000=0\n",
    "length1000_5000=0\n",
    "length5000_=0\n",
    "\n",
    "for i in glob.glob(input_dir+\"/*fa\"):\n",
    "    ls0_300=[]\n",
    "    ls300_500=[]\n",
    "    ls500_1000=[]\n",
    "    ls1000_5000=[]\n",
    "    ls5000_=[]\n",
    "    file_basename=os.path.splitext(os.path.basename(i))[0]\n",
    "    input_blastout=input_dir + \"/\" + file_basename + \".fa.blast.out\"\n",
    "    input_fa=i\n",
    "    \n",
    "    contigLen_1=get_contigLen(input_fa)\n",
    "    alignLen_1=get_alignLen(input_blastout)\n",
    "    tmp_list=[]\n",
    "    for i in alignLen_1:\n",
    "        if alignLen_1[i][0] >= 95 and (alignLen_1[i][1] / contigLen_1[i]) >= 0.95:\n",
    "            tmp_list.append(str(i))\n",
    "\n",
    "    a=tmp_list\n",
    "    subseq_dic=extract_subseq_dic(a,input_fa)\n",
    "    \n",
    "    for j in subseq_dic:\n",
    "        if subseq_dic[j] <=300:\n",
    "            length0_300 += 1\n",
    "            ls0_300.append(j)\n",
    "        elif 300<=subseq_dic[j] < 500:\n",
    "            length300_500 += 1\n",
    "            ls300_500.append(j)\n",
    "        elif 500 <= subseq_dic[j] < 1000:\n",
    "            length500_1000 += 1\n",
    "            ls500_1000.append(j)\n",
    "        elif 1000 <= subseq_dic[j] < 5000:\n",
    "            length1000_5000 += 1\n",
    "            ls1000_5000.append(j)\n",
    "        elif 5000 <= subseq_dic[j]:\n",
    "            length5000_ += 1    \n",
    "            ls5000_.append(j)\n",
    "        \n",
    "    # extract_subseq_lengthFilter(ls0_300,input_fa,\"0.3\")\n",
    "    extract_subseq_lengthFilter(ls300_500,input_fa,\"0.5\")\n",
    "    extract_subseq_lengthFilter(ls500_1000,input_fa,\"1\")\n",
    "    extract_subseq_lengthFilter(ls1000_5000,input_fa,\"5\")\n",
    "    extract_subseq_lengthFilter(ls5000_,input_fa,\"lt5\")\n",
    "        \n",
    "\n",
    "print(length0_300,\n",
    "length300_500,\n",
    "length500_1000,\n",
    "length1000_5000,\n",
    "length5000_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract target number of contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate fitered sequence \n",
    "input_dir=\"/lomi_home/gaoyang/software/CompRanking/benchmarking/MGE_benchmarking/plasclass/GT/chromosome\"\n",
    "for i in glob.glob(input_dir+\"/*fa\"):\n",
    "    file_basename=os.path.splitext(os.path.basename(i))[0]\n",
    "    input_fa=i\n",
    "    extract_subseq_nseq(600, input_fa)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aligenLen_dic={}\n",
    "# INPUT_BLASTOUT=pd.read_csv(input_blastout, sep='\\t', header=None)\n",
    "# INPUT_BLASTOUT.columns = ['id', 'sub_id', 'identity', 'alignLen', 'mismat', 'gapOpens', 'qStart', 'qEnd', 'sStart', 'sEnd', 'eval', 'bit']\n",
    "# INPUT_BLASTOUT\n",
    "# for i, record in INPUT_BLASTOUT.iterrows():\n",
    "#     aligenLen_dic.setdefault(str(record['id']), [int(record['identity']), int(record['alignLen'])])\n",
    "# aligenLen_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB_length=dict()\n",
    "#     try:\n",
    "#         for lines in open(file_name + '.length', 'r'):\n",
    "#             DB_length.setdefault(str(lines.split('\\t')[0]), len(str(lines.split('\\t')[-1]).replace('\\n','')))\n",
    "#     except (IOError,FileNotFoundError):\n",
    "#         Fasta_name = open(file_name, 'r')\n",
    "#         f = open(file_name + '.length', 'w')\n",
    "#         for record in SeqIO.parse(Fasta_name, 'fasta'):\n",
    "#             f.write(str(record.id) + '\\t'  + str(\n",
    "#                 len(record.seq)) + '\\n')\n",
    "#             DB_length.setdefault(str(record.id), len(str(record.seq)))\n",
    "#         f.close()\n",
    "#     return DB_length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:18) \n[GCC 10.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96a28c887955343dfdcfe0648667fa1d323b86bd8c9a5b8cfe9af24fde7c7749"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
